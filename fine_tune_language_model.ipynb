{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31972ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fafc1f35654a2bbb821838e88c8861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ccc130f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "from lib.hard_coded_constants import GENERATED_HEADLINES_FILE_NAME, DATA_FILE_NAME, BASE_LANGUAGE_MODEL, NEWS_SITES_BASE_URL, NEWS_CATEGORIES\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "\n",
    "base_model_checkpoint = BASE_LANGUAGE_MODEL\n",
    "base_model_tokenizer = AutoTokenizer.from_pretrained(base_model_checkpoint, use_fast=True)\n",
    "\n",
    "networks = list(NEWS_SITES_BASE_URL.keys())\n",
    "BLOCK_SIZE = 128\n",
    "STOP_CHAR = base_model_tokenizer.eos_token\n",
    "\n",
    "if base_model_tokenizer.pad_token is None:\n",
    "    base_model_tokenizer.pad_token = base_model_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b96ebb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tuned_model_name(network):\n",
    "    model_name = BASE_LANGUAGE_MODEL.split(\"/\")[-1]\n",
    "    fine_tuned_model = f\"{model_name}-finetuned-{network}\"\n",
    "    return fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b02f39d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breitbart split into 3731 headlines to fine-tune and 924 headline beginnings to generate new headlines\n",
      "Fox split into 5405 headlines to fine-tune and 1334 headline beginnings to generate new headlines\n",
      "MSNBC split into 1274 headlines to fine-tune and 319 headline beginnings to generate new headlines\n",
      "Newsmax split into 6840 headlines to fine-tune and 1667 headline beginnings to generate new headlines\n",
      "Nypost split into 5380 headlines to fine-tune and 1343 headline beginnings to generate new headlines\n",
      "NYT split into 5052 headlines to fine-tune and 1240 headline beginnings to generate new headlines\n",
      "USAToday split into 3220 headlines to fine-tune and 797 headline beginnings to generate new headlines\n",
      "Washpost split into 2715 headlines to fine-tune and 668 headline beginnings to generate new headlines\n",
      "WSJ split into 1647 headlines to fine-tune and 412 headline beginnings to generate new headlines\n"
     ]
    }
   ],
   "source": [
    "headlines_df = pd.read_csv(DATA_FILE_NAME)\n",
    "headlines_df = headlines_df[headlines_df[\"news_category\"] == \"politics\"]\n",
    "headlines_df = headlines_df[[\"network\", \"headline\"]]\n",
    "\n",
    "training_datasets = {}\n",
    "testing_headlines = {}\n",
    "for network in networks:\n",
    "    training_df, testing_df = train_test_split(headlines_df[headlines_df[\"network\"] == network], test_size=0.2, random_state=123)\n",
    "    training_df = training_df[[\"headline\"]]\n",
    "    training_df[\"headline\"] = training_df[\"headline\"].astype(str) + f\" {STOP_CHAR}\"\n",
    "    \n",
    "    training_data = Dataset.from_pandas(training_df, preserve_index=False)\n",
    "\n",
    "    testing_df[\"first_4_words_in_headline\"] = testing_df[\"headline\"].str.split().str[:4].str.join(\" \")\n",
    "    headlines = list(testing_df[\"first_4_words_in_headline\"].unique())\n",
    "\n",
    "    print(f\"{network} split into {len(training_data)} headlines to fine-tune and {len(headlines)} headline beginnings to generate new headlines\")\n",
    "\n",
    "    training_datasets[network] = training_data\n",
    "    testing_headlines[network] = headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "00fdbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(headlines):\n",
    "    return base_model_tokenizer(headlines[\"headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "22c03be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1739f7a9d6488f915b030705f71703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e93c0e5c7d4e59bbcc5cf28c62fa0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f181982e9ad4352b74ea51d86424dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cfb99bf84f49a1a1716cb7049aa436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/6840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f676d069ecc34a118cd89a857424af05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e220be834149938706a44b70068ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5052 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099f0b4680f3459a82f45d40f9a166b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ed1a9fd2a9439c87b4f6625ab1da43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18b88e14edc4670844ee483f2fb3bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I can do this with dictionary comprehension but I think it is more readable this way\n",
    "tokenized_datasets = {}\n",
    "for network in networks:\n",
    "    tokenized_datasets[network] = training_datasets[network].map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dbee0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // BLOCK_SIZE) * BLOCK_SIZE\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + BLOCK_SIZE] for i in range(0, total_length, BLOCK_SIZE)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ef22b7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9f29d63ec34f2d9f626346b0496fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b56b37dd743427aa4e88c3d44ba2dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809d780796004e0aba01a52adead5ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cadbfc88ad40bab7d937256afbef42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/6840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0640d3d0e36e44a8903c34f68b7d3f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70f79cac27849bd8c05841cf88733c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5052 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d725676c10df44129b4a1088cc8cba46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a248e0cbf63490d8bffdb279620e245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6868ec7883ec4d428c583dc172fb72a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = {}\n",
    "for network in networks:\n",
    "    lm_datasets[network] = tokenized_datasets[network].map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        num_proc=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "15d13a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_95918/3126651308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b013e66dd2134567b74da7b39f43bea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4c8303b6e149f8b5ec2a283ecc77f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_95918/3126651308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [324/324 01:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b366bdd1adbf4690b42292f1bb5fd21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dcfb9e65d344ac98f75e354d234954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_95918/3126651308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0709f9eb7040039c43440533d9bb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db820c2e089b48fca182725e55af8051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_95918/3126651308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='354' max='354' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [354/354 01:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e6638b32de40b595e3d14f85bedf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cbc3e1e1dd449488111d0bb1d691af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_95918/3126651308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [342/342 01:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a8af56690e4d348b233e2de8a77be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7cbded33984a2086515d0a477b31f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_95918/3126651308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [261/261 01:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff3433d56574a9abc2b3303780ffaf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d142ff0c2e94c3c9f344c92452005e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_95918/3126651308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [141/141 00:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11dba012fbb04c129ed814ad19d01f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9c18ffe4df4230aa6888b5bd68e9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_95918/3126651308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 00:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5addffe6254ea9809f924b266ba6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abbfb2d8b1b4164b846e7fc40514d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_95918/3126651308.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e59f8ca9784bdfad64d6f8b069ed08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aff536afc964ef4b68328fcaa084362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for network in networks:\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(base_model_checkpoint)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        fine_tuned_model_name(network),\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        push_to_hub=True,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=base_model,\n",
    "        args=training_args,\n",
    "        tokenizer=base_model_tokenizer,\n",
    "        train_dataset=lm_datasets[network],\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3c9256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device: cpu\n",
      "generating 924 headlines for Breitbart\n",
      "generating 924 headlines in 29 batches\n",
      "starting batch 1/29\n",
      "starting batch 2/29\n",
      "starting batch 3/29\n",
      "starting batch 4/29\n",
      "starting batch 5/29\n",
      "starting batch 6/29\n",
      "starting batch 7/29\n",
      "starting batch 8/29\n",
      "starting batch 9/29\n",
      "starting batch 10/29\n",
      "starting batch 11/29\n",
      "starting batch 12/29\n",
      "starting batch 13/29\n",
      "starting batch 14/29\n",
      "starting batch 15/29\n",
      "starting batch 16/29\n",
      "starting batch 17/29\n",
      "starting batch 18/29\n",
      "starting batch 19/29\n",
      "starting batch 20/29\n",
      "starting batch 21/29\n",
      "starting batch 22/29\n",
      "starting batch 23/29\n",
      "starting batch 24/29\n",
      "starting batch 25/29\n",
      "starting batch 26/29\n",
      "starting batch 27/29\n",
      "starting batch 28/29\n",
      "starting batch 29/29\n",
      "finished Breitbart\n",
      "running on device: cpu\n",
      "generating 1334 headlines for Fox\n",
      "generating 1334 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "finished Fox\n",
      "running on device: cpu\n",
      "generating 319 headlines for MSNBC\n",
      "generating 319 headlines in 10 batches\n",
      "starting batch 1/10\n",
      "starting batch 2/10\n",
      "starting batch 3/10\n",
      "starting batch 4/10\n",
      "starting batch 5/10\n",
      "starting batch 6/10\n",
      "starting batch 7/10\n",
      "starting batch 8/10\n",
      "starting batch 9/10\n",
      "starting batch 10/10\n",
      "finished MSNBC\n",
      "running on device: cpu\n",
      "generating 1667 headlines for Newsmax\n",
      "generating 1667 headlines in 53 batches\n",
      "starting batch 1/53\n",
      "starting batch 2/53\n",
      "starting batch 3/53\n",
      "starting batch 4/53\n",
      "starting batch 5/53\n",
      "starting batch 6/53\n",
      "starting batch 7/53\n",
      "starting batch 8/53\n",
      "starting batch 9/53\n",
      "starting batch 10/53\n",
      "starting batch 11/53\n",
      "starting batch 12/53\n",
      "starting batch 13/53\n",
      "starting batch 14/53\n",
      "starting batch 15/53\n",
      "starting batch 16/53\n",
      "starting batch 17/53\n",
      "starting batch 18/53\n",
      "starting batch 19/53\n",
      "starting batch 20/53\n",
      "starting batch 21/53\n",
      "starting batch 22/53\n",
      "starting batch 23/53\n",
      "starting batch 24/53\n",
      "starting batch 25/53\n",
      "starting batch 26/53\n",
      "starting batch 27/53\n",
      "starting batch 28/53\n",
      "starting batch 29/53\n",
      "starting batch 30/53\n",
      "starting batch 31/53\n",
      "starting batch 32/53\n",
      "starting batch 33/53\n",
      "starting batch 34/53\n",
      "starting batch 35/53\n",
      "starting batch 36/53\n",
      "starting batch 37/53\n",
      "starting batch 38/53\n",
      "starting batch 39/53\n",
      "starting batch 40/53\n",
      "starting batch 41/53\n",
      "starting batch 42/53\n",
      "starting batch 43/53\n",
      "starting batch 44/53\n",
      "starting batch 45/53\n",
      "starting batch 46/53\n",
      "starting batch 47/53\n",
      "starting batch 48/53\n",
      "starting batch 49/53\n",
      "starting batch 50/53\n",
      "starting batch 51/53\n",
      "starting batch 52/53\n",
      "starting batch 53/53\n",
      "finished Newsmax\n",
      "running on device: cpu\n",
      "generating 1343 headlines for Nypost\n",
      "generating 1343 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "finished Nypost\n",
      "running on device: cpu\n",
      "generating 1240 headlines for NYT\n",
      "generating 1240 headlines in 39 batches\n",
      "starting batch 1/39\n",
      "starting batch 2/39\n",
      "starting batch 3/39\n",
      "starting batch 4/39\n",
      "starting batch 5/39\n",
      "starting batch 6/39\n",
      "starting batch 7/39\n",
      "starting batch 8/39\n",
      "starting batch 9/39\n",
      "starting batch 10/39\n",
      "starting batch 11/39\n",
      "starting batch 12/39\n",
      "starting batch 13/39\n",
      "starting batch 14/39\n",
      "starting batch 15/39\n",
      "starting batch 16/39\n",
      "starting batch 17/39\n",
      "starting batch 18/39\n",
      "starting batch 19/39\n",
      "starting batch 20/39\n",
      "starting batch 21/39\n",
      "starting batch 22/39\n",
      "starting batch 23/39\n",
      "starting batch 24/39\n",
      "starting batch 25/39\n",
      "starting batch 26/39\n",
      "starting batch 27/39\n",
      "starting batch 28/39\n",
      "starting batch 29/39\n",
      "starting batch 30/39\n",
      "starting batch 31/39\n",
      "starting batch 32/39\n",
      "starting batch 33/39\n",
      "starting batch 34/39\n",
      "starting batch 35/39\n",
      "starting batch 36/39\n",
      "starting batch 37/39\n",
      "starting batch 38/39\n",
      "starting batch 39/39\n",
      "finished NYT\n",
      "running on device: cpu\n",
      "generating 797 headlines for USAToday\n",
      "generating 797 headlines in 25 batches\n",
      "starting batch 1/25\n",
      "starting batch 2/25\n",
      "starting batch 3/25\n",
      "starting batch 4/25\n",
      "starting batch 5/25\n",
      "starting batch 6/25\n",
      "starting batch 7/25\n",
      "starting batch 8/25\n",
      "starting batch 9/25\n",
      "starting batch 10/25\n",
      "starting batch 11/25\n",
      "starting batch 12/25\n",
      "starting batch 13/25\n",
      "starting batch 14/25\n",
      "starting batch 15/25\n",
      "starting batch 16/25\n",
      "starting batch 17/25\n",
      "starting batch 18/25\n",
      "starting batch 19/25\n",
      "starting batch 20/25\n",
      "starting batch 21/25\n",
      "starting batch 22/25\n",
      "starting batch 23/25\n",
      "starting batch 24/25\n",
      "starting batch 25/25\n",
      "finished USAToday\n",
      "running on device: cpu\n",
      "generating 668 headlines for Washpost\n",
      "generating 668 headlines in 21 batches\n",
      "starting batch 1/21\n",
      "starting batch 2/21\n",
      "starting batch 3/21\n",
      "starting batch 4/21\n",
      "starting batch 5/21\n",
      "starting batch 6/21\n",
      "starting batch 7/21\n",
      "starting batch 8/21\n",
      "starting batch 9/21\n",
      "starting batch 10/21\n",
      "starting batch 11/21\n",
      "starting batch 12/21\n",
      "starting batch 13/21\n",
      "starting batch 14/21\n",
      "starting batch 15/21\n",
      "starting batch 16/21\n",
      "starting batch 17/21\n",
      "starting batch 18/21\n",
      "starting batch 19/21\n",
      "starting batch 20/21\n",
      "starting batch 21/21\n",
      "finished Washpost\n",
      "running on device: cpu\n",
      "generating 412 headlines for WSJ\n",
      "generating 412 headlines in 13 batches\n",
      "starting batch 1/13\n",
      "starting batch 2/13\n",
      "starting batch 3/13\n",
      "starting batch 4/13\n",
      "starting batch 5/13\n",
      "starting batch 6/13\n",
      "starting batch 7/13\n",
      "starting batch 8/13\n",
      "starting batch 9/13\n",
      "starting batch 10/13\n",
      "starting batch 11/13\n",
      "starting batch 12/13\n",
      "starting batch 13/13\n",
      "finished WSJ\n"
     ]
    }
   ],
   "source": [
    "generated_headline_dfs = []\n",
    "\n",
    "for network in networks:\n",
    "    model_name = \"franzhanz/\" + fine_tuned_model_name(network)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    print(f\"running on device: {device}\")\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    headlines = testing_headlines[network]\n",
    "    print(f\"generating {len(headlines)} headlines for {network}\")\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    num_batches = (len(headlines) + batch_size - 1) // batch_size\n",
    "    print(f\"generating {len(headlines)} headlines in {num_batches} batches\")\n",
    "\n",
    "    generated_headlines = []\n",
    "    for i in range(num_batches):\n",
    "        print(f\"starting batch {i + 1}/{num_batches}\")\n",
    "\n",
    "        start = i * batch_size\n",
    "        end = min(start + batch_size, len(headlines))\n",
    "        batch_headlines = headlines[start:end]\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            batch_headlines,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=64\n",
    "        )\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=64,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            # min_new_tokens=8,\n",
    "            # repetition_penalty=1.2,\n",
    "            # no_repeat_ngram_size=3,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.9\n",
    "        )\n",
    "\n",
    "        results = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        results = [re.sub(r'\\s+', ' ', r).strip() for r in results]\n",
    "        generated_headlines += results\n",
    "\n",
    "    print(f\"finished {network}\")\n",
    "    generated_headlines = [headline.strip() for headline in generated_headlines]\n",
    "\n",
    "    generated_df = pd.DataFrame({\"headline\": generated_headlines})\n",
    "    generated_df[\"year\"] = 2025\n",
    "    generated_df[\"month\"] = 10\n",
    "    generated_df[\"day\"] = 10\n",
    "    generated_df[\"network\"] = network\n",
    "    generated_df[\"url\"] = \"generated_headline\"\n",
    "    generated_df[\"news_category\"] = \"politics\"\n",
    "\n",
    "    generated_headline_dfs.append(generated_df)\n",
    "\n",
    "pd.concat(generated_headline_dfs).to_csv(GENERATED_HEADLINES_FILE_NAME, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dd613ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding pos_neg_neu sentiment for Breitbart headlines on 2025-10-10\n",
      "added 924 pos_neg_neu sentiments for Breitbart headlines on 2025-10-10\n",
      "finding emotion sentiment for Breitbart headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 924 headlines in 29 batches\n",
      "starting batch 1/29\n",
      "starting batch 2/29\n",
      "starting batch 3/29\n",
      "starting batch 4/29\n",
      "starting batch 5/29\n",
      "starting batch 6/29\n",
      "starting batch 7/29\n",
      "starting batch 8/29\n",
      "starting batch 9/29\n",
      "starting batch 10/29\n",
      "starting batch 11/29\n",
      "starting batch 12/29\n",
      "starting batch 13/29\n",
      "starting batch 14/29\n",
      "starting batch 15/29\n",
      "starting batch 16/29\n",
      "starting batch 17/29\n",
      "starting batch 18/29\n",
      "starting batch 19/29\n",
      "starting batch 20/29\n",
      "starting batch 21/29\n",
      "starting batch 22/29\n",
      "starting batch 23/29\n",
      "starting batch 24/29\n",
      "starting batch 25/29\n",
      "starting batch 26/29\n",
      "starting batch 27/29\n",
      "starting batch 28/29\n",
      "starting batch 29/29\n",
      "Finished processing 924 headlines\n",
      "finding pos_neg_neu sentiment for Fox headlines on 2025-10-10\n",
      "added 1334 pos_neg_neu sentiments for Fox headlines on 2025-10-10\n",
      "finding emotion sentiment for Fox headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1334 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "Finished processing 1334 headlines\n",
      "finding pos_neg_neu sentiment for MSNBC headlines on 2025-10-10\n",
      "added 319 pos_neg_neu sentiments for MSNBC headlines on 2025-10-10\n",
      "finding emotion sentiment for MSNBC headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 319 headlines in 10 batches\n",
      "starting batch 1/10\n",
      "starting batch 2/10\n",
      "starting batch 3/10\n",
      "starting batch 4/10\n",
      "starting batch 5/10\n",
      "starting batch 6/10\n",
      "starting batch 7/10\n",
      "starting batch 8/10\n",
      "starting batch 9/10\n",
      "starting batch 10/10\n",
      "Finished processing 319 headlines\n",
      "finding pos_neg_neu sentiment for Newsmax headlines on 2025-10-10\n",
      "added 1667 pos_neg_neu sentiments for Newsmax headlines on 2025-10-10\n",
      "finding emotion sentiment for Newsmax headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1667 headlines in 53 batches\n",
      "starting batch 1/53\n",
      "starting batch 2/53\n",
      "starting batch 3/53\n",
      "starting batch 4/53\n",
      "starting batch 5/53\n",
      "starting batch 6/53\n",
      "starting batch 7/53\n",
      "starting batch 8/53\n",
      "starting batch 9/53\n",
      "starting batch 10/53\n",
      "starting batch 11/53\n",
      "starting batch 12/53\n",
      "starting batch 13/53\n",
      "starting batch 14/53\n",
      "starting batch 15/53\n",
      "starting batch 16/53\n",
      "starting batch 17/53\n",
      "starting batch 18/53\n",
      "starting batch 19/53\n",
      "starting batch 20/53\n",
      "starting batch 21/53\n",
      "starting batch 22/53\n",
      "starting batch 23/53\n",
      "starting batch 24/53\n",
      "starting batch 25/53\n",
      "starting batch 26/53\n",
      "starting batch 27/53\n",
      "starting batch 28/53\n",
      "starting batch 29/53\n",
      "starting batch 30/53\n",
      "starting batch 31/53\n",
      "starting batch 32/53\n",
      "starting batch 33/53\n",
      "starting batch 34/53\n",
      "starting batch 35/53\n",
      "starting batch 36/53\n",
      "starting batch 37/53\n",
      "starting batch 38/53\n",
      "starting batch 39/53\n",
      "starting batch 40/53\n",
      "starting batch 41/53\n",
      "starting batch 42/53\n",
      "starting batch 43/53\n",
      "starting batch 44/53\n",
      "starting batch 45/53\n",
      "starting batch 46/53\n",
      "starting batch 47/53\n",
      "starting batch 48/53\n",
      "starting batch 49/53\n",
      "starting batch 50/53\n",
      "starting batch 51/53\n",
      "starting batch 52/53\n",
      "starting batch 53/53\n",
      "Finished processing 1667 headlines\n",
      "finding pos_neg_neu sentiment for Nypost headlines on 2025-10-10\n",
      "added 1343 pos_neg_neu sentiments for Nypost headlines on 2025-10-10\n",
      "finding emotion sentiment for Nypost headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1343 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "Finished processing 1343 headlines\n",
      "finding pos_neg_neu sentiment for NYT headlines on 2025-10-10\n",
      "added 1240 pos_neg_neu sentiments for NYT headlines on 2025-10-10\n",
      "finding emotion sentiment for NYT headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1240 headlines in 39 batches\n",
      "starting batch 1/39\n",
      "starting batch 2/39\n",
      "starting batch 3/39\n",
      "starting batch 4/39\n",
      "starting batch 5/39\n",
      "starting batch 6/39\n",
      "starting batch 7/39\n",
      "starting batch 8/39\n",
      "starting batch 9/39\n",
      "starting batch 10/39\n",
      "starting batch 11/39\n",
      "starting batch 12/39\n",
      "starting batch 13/39\n",
      "starting batch 14/39\n",
      "starting batch 15/39\n",
      "starting batch 16/39\n",
      "starting batch 17/39\n",
      "starting batch 18/39\n",
      "starting batch 19/39\n",
      "starting batch 20/39\n",
      "starting batch 21/39\n",
      "starting batch 22/39\n",
      "starting batch 23/39\n",
      "starting batch 24/39\n",
      "starting batch 25/39\n",
      "starting batch 26/39\n",
      "starting batch 27/39\n",
      "starting batch 28/39\n",
      "starting batch 29/39\n",
      "starting batch 30/39\n",
      "starting batch 31/39\n",
      "starting batch 32/39\n",
      "starting batch 33/39\n",
      "starting batch 34/39\n",
      "starting batch 35/39\n",
      "starting batch 36/39\n",
      "starting batch 37/39\n",
      "starting batch 38/39\n",
      "starting batch 39/39\n",
      "Finished processing 1240 headlines\n",
      "finding pos_neg_neu sentiment for USAToday headlines on 2025-10-10\n",
      "added 797 pos_neg_neu sentiments for USAToday headlines on 2025-10-10\n",
      "finding emotion sentiment for USAToday headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 797 headlines in 25 batches\n",
      "starting batch 1/25\n",
      "starting batch 2/25\n",
      "starting batch 3/25\n",
      "starting batch 4/25\n",
      "starting batch 5/25\n",
      "starting batch 6/25\n",
      "starting batch 7/25\n",
      "starting batch 8/25\n",
      "starting batch 9/25\n",
      "starting batch 10/25\n",
      "starting batch 11/25\n",
      "starting batch 12/25\n",
      "starting batch 13/25\n",
      "starting batch 14/25\n",
      "starting batch 15/25\n",
      "starting batch 16/25\n",
      "starting batch 17/25\n",
      "starting batch 18/25\n",
      "starting batch 19/25\n",
      "starting batch 20/25\n",
      "starting batch 21/25\n",
      "starting batch 22/25\n",
      "starting batch 23/25\n",
      "starting batch 24/25\n",
      "starting batch 25/25\n",
      "Finished processing 797 headlines\n",
      "finding pos_neg_neu sentiment for Washpost headlines on 2025-10-10\n",
      "added 668 pos_neg_neu sentiments for Washpost headlines on 2025-10-10\n",
      "finding emotion sentiment for Washpost headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 668 headlines in 21 batches\n",
      "starting batch 1/21\n",
      "starting batch 2/21\n",
      "starting batch 3/21\n",
      "starting batch 4/21\n",
      "starting batch 5/21\n",
      "starting batch 6/21\n",
      "starting batch 7/21\n",
      "starting batch 8/21\n",
      "starting batch 9/21\n",
      "starting batch 10/21\n",
      "starting batch 11/21\n",
      "starting batch 12/21\n",
      "starting batch 13/21\n",
      "starting batch 14/21\n",
      "starting batch 15/21\n",
      "starting batch 16/21\n",
      "starting batch 17/21\n",
      "starting batch 18/21\n",
      "starting batch 19/21\n",
      "starting batch 20/21\n",
      "starting batch 21/21\n",
      "Finished processing 668 headlines\n",
      "finding pos_neg_neu sentiment for WSJ headlines on 2025-10-10\n",
      "added 412 pos_neg_neu sentiments for WSJ headlines on 2025-10-10\n",
      "finding emotion sentiment for WSJ headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 412 headlines in 13 batches\n",
      "starting batch 1/13\n",
      "starting batch 2/13\n",
      "starting batch 3/13\n",
      "starting batch 4/13\n",
      "starting batch 5/13\n",
      "starting batch 6/13\n",
      "starting batch 7/13\n",
      "starting batch 8/13\n",
      "starting batch 9/13\n",
      "starting batch 10/13\n",
      "starting batch 11/13\n",
      "starting batch 12/13\n",
      "starting batch 13/13\n",
      "Finished processing 412 headlines\n"
     ]
    }
   ],
   "source": [
    "from lib.sentiment_analysis import find_pos_neg_neu_sentiment, find_emotion_sentiment\n",
    "\n",
    "for network in networks:\n",
    "    find_pos_neg_neu_sentiment(network, 2025, 10, 10, use_generated_headlines=True)\n",
    "    find_emotion_sentiment(network, 2025, 10, 10, use_generated_headlines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
