{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31972ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc130f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib.hard_coded_constants'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-799384893.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhard_coded_constants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGENERATED_HEADLINES_FILE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_FILE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_LANGUAGE_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEWS_SITES_BASE_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEWS_CATEGORIES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lib.hard_coded_constants'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "from lib.hard_coded_constants import GENERATED_HEADLINES_FILE_NAME, DATA_FILE_NAME, BASE_LANGUAGE_MODEL, NEWS_SITES_BASE_URL, NEWS_CATEGORIES\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "\n",
    "base_model_checkpoint = BASE_LANGUAGE_MODEL\n",
    "base_model_tokenizer = AutoTokenizer.from_pretrained(base_model_checkpoint, use_fast=True)\n",
    "\n",
    "networks = list(NEWS_SITES_BASE_URL.keys())\n",
    "BLOCK_SIZE = 128\n",
    "STOP_CHAR = base_model_tokenizer.eos_token\n",
    "\n",
    "if base_model_tokenizer.pad_token is None:\n",
    "    base_model_tokenizer.pad_token = base_model_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96ebb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tuned_model_name(network):\n",
    "    model_name = BASE_LANGUAGE_MODEL.split(\"/\")[-1]\n",
    "    fine_tuned_model = f\"{model_name}-finetuned-{network}\"\n",
    "    return fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02f39d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breitbart split into 3731 headlines to fine-tune and 924 headline beginnings to generate new headlines\n",
      "Fox split into 5405 headlines to fine-tune and 1334 headline beginnings to generate new headlines\n",
      "MSNBC split into 1274 headlines to fine-tune and 319 headline beginnings to generate new headlines\n",
      "Newsmax split into 6840 headlines to fine-tune and 1667 headline beginnings to generate new headlines\n",
      "Nypost split into 5380 headlines to fine-tune and 1343 headline beginnings to generate new headlines\n",
      "NYT split into 5052 headlines to fine-tune and 1240 headline beginnings to generate new headlines\n",
      "USAToday split into 3220 headlines to fine-tune and 797 headline beginnings to generate new headlines\n",
      "Washpost split into 2715 headlines to fine-tune and 668 headline beginnings to generate new headlines\n",
      "WSJ split into 1647 headlines to fine-tune and 412 headline beginnings to generate new headlines\n"
     ]
    }
   ],
   "source": [
    "headlines_df = pd.read_csv(DATA_FILE_NAME)\n",
    "headlines_df = headlines_df[headlines_df[\"news_category\"] == \"politics\"]\n",
    "headlines_df = headlines_df[[\"network\", \"headline\"]]\n",
    "\n",
    "training_datasets = {}\n",
    "testing_headlines = {}\n",
    "for network in networks:\n",
    "    training_df, testing_df = train_test_split(headlines_df[headlines_df[\"network\"] == network], test_size=0.2, random_state=123)\n",
    "    training_df = training_df[[\"headline\"]]\n",
    "    training_df[\"headline\"] = training_df[\"headline\"].astype(str) + f\" {STOP_CHAR}\"\n",
    "    \n",
    "    training_data = Dataset.from_pandas(training_df, preserve_index=False)\n",
    "\n",
    "    testing_df[\"first_4_words_in_headline\"] = testing_df[\"headline\"].str.split().str[:4].str.join(\" \")\n",
    "    headlines = list(testing_df[\"first_4_words_in_headline\"].unique())\n",
    "\n",
    "    print(f\"{network} split into {len(training_data)} headlines to fine-tune and {len(headlines)} headline beginnings to generate new headlines\")\n",
    "\n",
    "    training_datasets[network] = training_data\n",
    "    testing_headlines[network] = headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00fdbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(headlines):\n",
    "    return base_model_tokenizer(headlines[\"headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22c03be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e195857ccf45e2b325483da0d8b1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8450016ad13a4cc4bb2f4922fbada96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c540f7d67a8454080d8c822063b99a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73edeb5d96934aa888e911d6735afd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/6840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63beadc693147efab6bb3a38d5da98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d80b66ebb97429d8bb74005fda8ecd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5052 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ec90e98e0f4de2be8aeb1f1bb945ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a52ca14b9c408eb1e1b2fa3107decd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665e3cdee8f044c3a5f7433185f6fdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I can do this with dictionary comprehension but I think it is more readable this way\n",
    "tokenized_datasets = {}\n",
    "for network in networks:\n",
    "    tokenized_datasets[network] = training_datasets[network].map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbee0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // BLOCK_SIZE) * BLOCK_SIZE\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + BLOCK_SIZE] for i in range(0, total_length, BLOCK_SIZE)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef22b7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19e2653633444b0bb2177b05a246542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f898c85822242f3aec7cc2e131ef475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a34bc2bd7548c3a791a21652b7ff2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6729eb8a9b014055bc70cad5b4095711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/6840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf92cf7530c4678ba8850298482d5f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcef106e17943bba748f55eb3c9f362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5052 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bab090e0d94cd2841a2dc81c7ae93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447be8f3cf6944768712de5bea803cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8b4ce61ccc4bc398c4239e5b65f183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = {}\n",
    "for network in networks:\n",
    "    lm_datasets[network] = tokenized_datasets[network].map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        num_proc=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15d13a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_70605/3174834110.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 00:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_70605/3174834110.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [324/324 01:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_70605/3174834110.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [69/69 00:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_70605/3174834110.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='354' max='354' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [354/354 01:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_70605/3174834110.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [342/342 01:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_70605/3174834110.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [261/261 01:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_70605/3174834110.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [141/141 00:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_70605/3174834110.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [129/129 00:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_70605/3174834110.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for network in networks:\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(base_model_checkpoint)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        fine_tuned_model_name(network),\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        # push_to_hub=True,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=base_model,\n",
    "        args=training_args,\n",
    "        tokenizer=base_model_tokenizer,\n",
    "        train_dataset=lm_datasets[network],\n",
    "    )\n",
    "    trainer.train()\n",
    "    # trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3c9256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device: cpu\n",
      "generating 924 headlines for Breitbart\n",
      "generating 924 headlines in 29 batches\n",
      "starting batch 1/29\n",
      "starting batch 2/29\n",
      "starting batch 3/29\n",
      "starting batch 4/29\n",
      "starting batch 5/29\n",
      "starting batch 6/29\n",
      "starting batch 7/29\n",
      "starting batch 8/29\n",
      "starting batch 9/29\n",
      "starting batch 10/29\n",
      "starting batch 11/29\n",
      "starting batch 12/29\n",
      "starting batch 13/29\n",
      "starting batch 14/29\n",
      "starting batch 15/29\n",
      "starting batch 16/29\n",
      "starting batch 17/29\n",
      "starting batch 18/29\n",
      "starting batch 19/29\n",
      "starting batch 20/29\n",
      "starting batch 21/29\n",
      "starting batch 22/29\n",
      "starting batch 23/29\n",
      "starting batch 24/29\n",
      "starting batch 25/29\n",
      "starting batch 26/29\n",
      "starting batch 27/29\n",
      "starting batch 28/29\n",
      "starting batch 29/29\n",
      "finished Breitbart\n",
      "running on device: cpu\n",
      "generating 1334 headlines for Fox\n",
      "generating 1334 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "finished Fox\n",
      "running on device: cpu\n",
      "generating 319 headlines for MSNBC\n",
      "generating 319 headlines in 10 batches\n",
      "starting batch 1/10\n",
      "starting batch 2/10\n",
      "starting batch 3/10\n",
      "starting batch 4/10\n",
      "starting batch 5/10\n",
      "starting batch 6/10\n",
      "starting batch 7/10\n",
      "starting batch 8/10\n",
      "starting batch 9/10\n",
      "starting batch 10/10\n",
      "finished MSNBC\n",
      "running on device: cpu\n",
      "generating 1667 headlines for Newsmax\n",
      "generating 1667 headlines in 53 batches\n",
      "starting batch 1/53\n",
      "starting batch 2/53\n",
      "starting batch 3/53\n",
      "starting batch 4/53\n",
      "starting batch 5/53\n",
      "starting batch 6/53\n",
      "starting batch 7/53\n",
      "starting batch 8/53\n",
      "starting batch 9/53\n",
      "starting batch 10/53\n",
      "starting batch 11/53\n",
      "starting batch 12/53\n",
      "starting batch 13/53\n",
      "starting batch 14/53\n",
      "starting batch 15/53\n",
      "starting batch 16/53\n",
      "starting batch 17/53\n",
      "starting batch 18/53\n",
      "starting batch 19/53\n",
      "starting batch 20/53\n",
      "starting batch 21/53\n",
      "starting batch 22/53\n",
      "starting batch 23/53\n",
      "starting batch 24/53\n",
      "starting batch 25/53\n",
      "starting batch 26/53\n",
      "starting batch 27/53\n",
      "starting batch 28/53\n",
      "starting batch 29/53\n",
      "starting batch 30/53\n",
      "starting batch 31/53\n",
      "starting batch 32/53\n",
      "starting batch 33/53\n",
      "starting batch 34/53\n",
      "starting batch 35/53\n",
      "starting batch 36/53\n",
      "starting batch 37/53\n",
      "starting batch 38/53\n",
      "starting batch 39/53\n",
      "starting batch 40/53\n",
      "starting batch 41/53\n",
      "starting batch 42/53\n",
      "starting batch 43/53\n",
      "starting batch 44/53\n",
      "starting batch 45/53\n",
      "starting batch 46/53\n",
      "starting batch 47/53\n",
      "starting batch 48/53\n",
      "starting batch 49/53\n",
      "starting batch 50/53\n",
      "starting batch 51/53\n",
      "starting batch 52/53\n",
      "starting batch 53/53\n",
      "finished Newsmax\n",
      "running on device: cpu\n",
      "generating 1343 headlines for Nypost\n",
      "generating 1343 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "finished Nypost\n",
      "running on device: cpu\n",
      "generating 1240 headlines for NYT\n",
      "generating 1240 headlines in 39 batches\n",
      "starting batch 1/39\n",
      "starting batch 2/39\n",
      "starting batch 3/39\n",
      "starting batch 4/39\n",
      "starting batch 5/39\n",
      "starting batch 6/39\n",
      "starting batch 7/39\n",
      "starting batch 8/39\n",
      "starting batch 9/39\n",
      "starting batch 10/39\n",
      "starting batch 11/39\n",
      "starting batch 12/39\n",
      "starting batch 13/39\n",
      "starting batch 14/39\n",
      "starting batch 15/39\n",
      "starting batch 16/39\n",
      "starting batch 17/39\n",
      "starting batch 18/39\n",
      "starting batch 19/39\n",
      "starting batch 20/39\n",
      "starting batch 21/39\n",
      "starting batch 22/39\n",
      "starting batch 23/39\n",
      "starting batch 24/39\n",
      "starting batch 25/39\n",
      "starting batch 26/39\n",
      "starting batch 27/39\n",
      "starting batch 28/39\n",
      "starting batch 29/39\n",
      "starting batch 30/39\n",
      "starting batch 31/39\n",
      "starting batch 32/39\n",
      "starting batch 33/39\n",
      "starting batch 34/39\n",
      "starting batch 35/39\n",
      "starting batch 36/39\n",
      "starting batch 37/39\n",
      "starting batch 38/39\n",
      "starting batch 39/39\n",
      "finished NYT\n",
      "running on device: cpu\n",
      "generating 797 headlines for USAToday\n",
      "generating 797 headlines in 25 batches\n",
      "starting batch 1/25\n",
      "starting batch 2/25\n",
      "starting batch 3/25\n",
      "starting batch 4/25\n",
      "starting batch 5/25\n",
      "starting batch 6/25\n",
      "starting batch 7/25\n",
      "starting batch 8/25\n",
      "starting batch 9/25\n",
      "starting batch 10/25\n",
      "starting batch 11/25\n",
      "starting batch 12/25\n",
      "starting batch 13/25\n",
      "starting batch 14/25\n",
      "starting batch 15/25\n",
      "starting batch 16/25\n",
      "starting batch 17/25\n",
      "starting batch 18/25\n",
      "starting batch 19/25\n",
      "starting batch 20/25\n",
      "starting batch 21/25\n",
      "starting batch 22/25\n",
      "starting batch 23/25\n",
      "starting batch 24/25\n",
      "starting batch 25/25\n",
      "finished USAToday\n",
      "running on device: cpu\n",
      "generating 668 headlines for Washpost\n",
      "generating 668 headlines in 21 batches\n",
      "starting batch 1/21\n",
      "starting batch 2/21\n",
      "starting batch 3/21\n",
      "starting batch 4/21\n",
      "starting batch 5/21\n",
      "starting batch 6/21\n",
      "starting batch 7/21\n",
      "starting batch 8/21\n",
      "starting batch 9/21\n",
      "starting batch 10/21\n",
      "starting batch 11/21\n",
      "starting batch 12/21\n",
      "starting batch 13/21\n",
      "starting batch 14/21\n",
      "starting batch 15/21\n",
      "starting batch 16/21\n",
      "starting batch 17/21\n",
      "starting batch 18/21\n",
      "starting batch 19/21\n",
      "starting batch 20/21\n",
      "starting batch 21/21\n",
      "finished Washpost\n",
      "running on device: cpu\n",
      "generating 412 headlines for WSJ\n",
      "generating 412 headlines in 13 batches\n",
      "starting batch 1/13\n",
      "starting batch 2/13\n",
      "starting batch 3/13\n",
      "starting batch 4/13\n",
      "starting batch 5/13\n",
      "starting batch 6/13\n",
      "starting batch 7/13\n",
      "starting batch 8/13\n",
      "starting batch 9/13\n",
      "starting batch 10/13\n",
      "starting batch 11/13\n",
      "starting batch 12/13\n",
      "starting batch 13/13\n",
      "finished WSJ\n"
     ]
    }
   ],
   "source": [
    "generated_headline_dfs = []\n",
    "\n",
    "for network in networks:\n",
    "    model_name = \"franzhanz/\" + fine_tuned_model_name(network)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    print(f\"running on device: {device}\")\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    headlines = testing_headlines[network]\n",
    "    print(f\"generating {len(headlines)} headlines for {network}\")\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    num_batches = (len(headlines) + batch_size - 1) // batch_size\n",
    "    print(f\"generating {len(headlines)} headlines in {num_batches} batches\")\n",
    "\n",
    "    generated_headlines = []\n",
    "    for i in range(num_batches):\n",
    "        print(f\"starting batch {i + 1}/{num_batches}\")\n",
    "\n",
    "        start = i * batch_size\n",
    "        end = min(start + batch_size, len(headlines))\n",
    "        batch_headlines = headlines[start:end]\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            batch_headlines,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=64\n",
    "        )\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=64,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.9\n",
    "        )\n",
    "\n",
    "        results = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        results = [re.sub(r'\\s+', ' ', r).strip() for r in results]\n",
    "        generated_headlines += results\n",
    "\n",
    "    print(f\"finished {network}\")\n",
    "    generated_headlines = [headline.strip() for headline in generated_headlines]\n",
    "\n",
    "    generated_df = pd.DataFrame({\"headline\": generated_headlines})\n",
    "    generated_df[\"year\"] = 2025\n",
    "    generated_df[\"month\"] = 10\n",
    "    generated_df[\"day\"] = 10\n",
    "    generated_df[\"network\"] = network\n",
    "    generated_df[\"url\"] = \"generated_headline\"\n",
    "    generated_df[\"news_category\"] = \"politics\"\n",
    "\n",
    "    generated_headline_dfs.append(generated_df)\n",
    "\n",
    "pd.concat(generated_headline_dfs).to_csv(GENERATED_HEADLINES_FILE_NAME, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd613ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding pos_neg_neu sentiment for Breitbart headlines on 2025-10-10\n",
      "added 924 pos_neg_neu sentiments for Breitbart headlines on 2025-10-10\n",
      "finding emotion sentiment for Breitbart headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 924 headlines in 29 batches\n",
      "starting batch 1/29\n",
      "starting batch 2/29\n",
      "starting batch 3/29\n",
      "starting batch 4/29\n",
      "starting batch 5/29\n",
      "starting batch 6/29\n",
      "starting batch 7/29\n",
      "starting batch 8/29\n",
      "starting batch 9/29\n",
      "starting batch 10/29\n",
      "starting batch 11/29\n",
      "starting batch 12/29\n",
      "starting batch 13/29\n",
      "starting batch 14/29\n",
      "starting batch 15/29\n",
      "starting batch 16/29\n",
      "starting batch 17/29\n",
      "starting batch 18/29\n",
      "starting batch 19/29\n",
      "starting batch 20/29\n",
      "starting batch 21/29\n",
      "starting batch 22/29\n",
      "starting batch 23/29\n",
      "starting batch 24/29\n",
      "starting batch 25/29\n",
      "starting batch 26/29\n",
      "starting batch 27/29\n",
      "starting batch 28/29\n",
      "starting batch 29/29\n",
      "Finished processing 924 headlines\n",
      "finding pos_neg_neu sentiment for Fox headlines on 2025-10-10\n",
      "added 1334 pos_neg_neu sentiments for Fox headlines on 2025-10-10\n",
      "finding emotion sentiment for Fox headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1334 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "Finished processing 1334 headlines\n",
      "finding pos_neg_neu sentiment for MSNBC headlines on 2025-10-10\n",
      "added 319 pos_neg_neu sentiments for MSNBC headlines on 2025-10-10\n",
      "finding emotion sentiment for MSNBC headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 319 headlines in 10 batches\n",
      "starting batch 1/10\n",
      "starting batch 2/10\n",
      "starting batch 3/10\n",
      "starting batch 4/10\n",
      "starting batch 5/10\n",
      "starting batch 6/10\n",
      "starting batch 7/10\n",
      "starting batch 8/10\n",
      "starting batch 9/10\n",
      "starting batch 10/10\n",
      "Finished processing 319 headlines\n",
      "finding pos_neg_neu sentiment for Newsmax headlines on 2025-10-10\n",
      "added 1667 pos_neg_neu sentiments for Newsmax headlines on 2025-10-10\n",
      "finding emotion sentiment for Newsmax headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1667 headlines in 53 batches\n",
      "starting batch 1/53\n",
      "starting batch 2/53\n",
      "starting batch 3/53\n",
      "starting batch 4/53\n",
      "starting batch 5/53\n",
      "starting batch 6/53\n",
      "starting batch 7/53\n",
      "starting batch 8/53\n",
      "starting batch 9/53\n",
      "starting batch 10/53\n",
      "starting batch 11/53\n",
      "starting batch 12/53\n",
      "starting batch 13/53\n",
      "starting batch 14/53\n",
      "starting batch 15/53\n",
      "starting batch 16/53\n",
      "starting batch 17/53\n",
      "starting batch 18/53\n",
      "starting batch 19/53\n",
      "starting batch 20/53\n",
      "starting batch 21/53\n",
      "starting batch 22/53\n",
      "starting batch 23/53\n",
      "starting batch 24/53\n",
      "starting batch 25/53\n",
      "starting batch 26/53\n",
      "starting batch 27/53\n",
      "starting batch 28/53\n",
      "starting batch 29/53\n",
      "starting batch 30/53\n",
      "starting batch 31/53\n",
      "starting batch 32/53\n",
      "starting batch 33/53\n",
      "starting batch 34/53\n",
      "starting batch 35/53\n",
      "starting batch 36/53\n",
      "starting batch 37/53\n",
      "starting batch 38/53\n",
      "starting batch 39/53\n",
      "starting batch 40/53\n",
      "starting batch 41/53\n",
      "starting batch 42/53\n",
      "starting batch 43/53\n",
      "starting batch 44/53\n",
      "starting batch 45/53\n",
      "starting batch 46/53\n",
      "starting batch 47/53\n",
      "starting batch 48/53\n",
      "starting batch 49/53\n",
      "starting batch 50/53\n",
      "starting batch 51/53\n",
      "starting batch 52/53\n",
      "starting batch 53/53\n",
      "Finished processing 1667 headlines\n",
      "finding pos_neg_neu sentiment for Nypost headlines on 2025-10-10\n",
      "added 1343 pos_neg_neu sentiments for Nypost headlines on 2025-10-10\n",
      "finding emotion sentiment for Nypost headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1343 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "Finished processing 1343 headlines\n",
      "finding pos_neg_neu sentiment for NYT headlines on 2025-10-10\n",
      "added 1240 pos_neg_neu sentiments for NYT headlines on 2025-10-10\n",
      "finding emotion sentiment for NYT headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1240 headlines in 39 batches\n",
      "starting batch 1/39\n",
      "starting batch 2/39\n",
      "starting batch 3/39\n",
      "starting batch 4/39\n",
      "starting batch 5/39\n",
      "starting batch 6/39\n",
      "starting batch 7/39\n",
      "starting batch 8/39\n",
      "starting batch 9/39\n",
      "starting batch 10/39\n",
      "starting batch 11/39\n",
      "starting batch 12/39\n",
      "starting batch 13/39\n",
      "starting batch 14/39\n",
      "starting batch 15/39\n",
      "starting batch 16/39\n",
      "starting batch 17/39\n",
      "starting batch 18/39\n",
      "starting batch 19/39\n",
      "starting batch 20/39\n",
      "starting batch 21/39\n",
      "starting batch 22/39\n",
      "starting batch 23/39\n",
      "starting batch 24/39\n",
      "starting batch 25/39\n",
      "starting batch 26/39\n",
      "starting batch 27/39\n",
      "starting batch 28/39\n",
      "starting batch 29/39\n",
      "starting batch 30/39\n",
      "starting batch 31/39\n",
      "starting batch 32/39\n",
      "starting batch 33/39\n",
      "starting batch 34/39\n",
      "starting batch 35/39\n",
      "starting batch 36/39\n",
      "starting batch 37/39\n",
      "starting batch 38/39\n",
      "starting batch 39/39\n",
      "Finished processing 1240 headlines\n",
      "finding pos_neg_neu sentiment for USAToday headlines on 2025-10-10\n",
      "added 797 pos_neg_neu sentiments for USAToday headlines on 2025-10-10\n",
      "finding emotion sentiment for USAToday headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 797 headlines in 25 batches\n",
      "starting batch 1/25\n",
      "starting batch 2/25\n",
      "starting batch 3/25\n",
      "starting batch 4/25\n",
      "starting batch 5/25\n",
      "starting batch 6/25\n",
      "starting batch 7/25\n",
      "starting batch 8/25\n",
      "starting batch 9/25\n",
      "starting batch 10/25\n",
      "starting batch 11/25\n",
      "starting batch 12/25\n",
      "starting batch 13/25\n",
      "starting batch 14/25\n",
      "starting batch 15/25\n",
      "starting batch 16/25\n",
      "starting batch 17/25\n",
      "starting batch 18/25\n",
      "starting batch 19/25\n",
      "starting batch 20/25\n",
      "starting batch 21/25\n",
      "starting batch 22/25\n",
      "starting batch 23/25\n",
      "starting batch 24/25\n",
      "starting batch 25/25\n",
      "Finished processing 797 headlines\n",
      "finding pos_neg_neu sentiment for Washpost headlines on 2025-10-10\n",
      "added 668 pos_neg_neu sentiments for Washpost headlines on 2025-10-10\n",
      "finding emotion sentiment for Washpost headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 668 headlines in 21 batches\n",
      "starting batch 1/21\n",
      "starting batch 2/21\n",
      "starting batch 3/21\n",
      "starting batch 4/21\n",
      "starting batch 5/21\n",
      "starting batch 6/21\n",
      "starting batch 7/21\n",
      "starting batch 8/21\n",
      "starting batch 9/21\n",
      "starting batch 10/21\n",
      "starting batch 11/21\n",
      "starting batch 12/21\n",
      "starting batch 13/21\n",
      "starting batch 14/21\n",
      "starting batch 15/21\n",
      "starting batch 16/21\n",
      "starting batch 17/21\n",
      "starting batch 18/21\n",
      "starting batch 19/21\n",
      "starting batch 20/21\n",
      "starting batch 21/21\n",
      "Finished processing 668 headlines\n",
      "finding pos_neg_neu sentiment for WSJ headlines on 2025-10-10\n",
      "added 412 pos_neg_neu sentiments for WSJ headlines on 2025-10-10\n",
      "finding emotion sentiment for WSJ headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 412 headlines in 13 batches\n",
      "starting batch 1/13\n",
      "starting batch 2/13\n",
      "starting batch 3/13\n",
      "starting batch 4/13\n",
      "starting batch 5/13\n",
      "starting batch 6/13\n",
      "starting batch 7/13\n",
      "starting batch 8/13\n",
      "starting batch 9/13\n",
      "starting batch 10/13\n",
      "starting batch 11/13\n",
      "starting batch 12/13\n",
      "starting batch 13/13\n",
      "Finished processing 412 headlines\n"
     ]
    }
   ],
   "source": [
    "from lib.sentiment_analysis import find_pos_neg_neu_sentiment, find_emotion_sentiment\n",
    "\n",
    "for network in networks:\n",
    "    find_pos_neg_neu_sentiment(network, 2025, 10, 10, use_generated_headlines=True)\n",
    "    find_emotion_sentiment(network, 2025, 10, 10, use_generated_headlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90937467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
