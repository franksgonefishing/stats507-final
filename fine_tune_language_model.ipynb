{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31972ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc130f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "from lib.hard_coded_constants import GENERATED_HEADLINES_FILE_NAME, DATA_FILE_NAME, BASE_LANGUAGE_MODEL, NEWS_SITES_BASE_URL, NEWS_CATEGORIES\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import math\n",
    "\n",
    "base_model_checkpoint = BASE_LANGUAGE_MODEL\n",
    "base_model_tokenizer = AutoTokenizer.from_pretrained(base_model_checkpoint, use_fast=True)\n",
    "\n",
    "networks = list(NEWS_SITES_BASE_URL.keys())\n",
    "BLOCK_SIZE = 128\n",
    "STOP_CHAR = base_model_tokenizer.eos_token\n",
    "\n",
    "if base_model_tokenizer.pad_token is None:\n",
    "    base_model_tokenizer.pad_token = base_model_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b96ebb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tuned_model_name(network):\n",
    "    model_name = BASE_LANGUAGE_MODEL.split(\"/\")[-1]\n",
    "    fine_tuned_model = f\"{model_name}-finetuned-{network}\"\n",
    "    return fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02f39d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breitbart split into 3731 headlines to fine-tune and 924 headline beginnings to generate new headlines\n",
      "Fox split into 5405 headlines to fine-tune and 1334 headline beginnings to generate new headlines\n",
      "MSNBC split into 1274 headlines to fine-tune and 319 headline beginnings to generate new headlines\n",
      "Newsmax split into 6840 headlines to fine-tune and 1667 headline beginnings to generate new headlines\n",
      "Nypost split into 5380 headlines to fine-tune and 1343 headline beginnings to generate new headlines\n",
      "NYT split into 5052 headlines to fine-tune and 1240 headline beginnings to generate new headlines\n",
      "USAToday split into 3220 headlines to fine-tune and 797 headline beginnings to generate new headlines\n",
      "Washpost split into 2715 headlines to fine-tune and 668 headline beginnings to generate new headlines\n",
      "WSJ split into 1647 headlines to fine-tune and 412 headline beginnings to generate new headlines\n"
     ]
    }
   ],
   "source": [
    "headlines_df = pd.read_csv(DATA_FILE_NAME)\n",
    "headlines_df = headlines_df[headlines_df[\"news_category\"] == \"politics\"]\n",
    "headlines_df = headlines_df[[\"network\", \"headline\"]]\n",
    "\n",
    "training_datasets = {}\n",
    "testing_headlines = {}\n",
    "for network in networks:\n",
    "    # 80/20 training testing split\n",
    "    training_df, testing_df = train_test_split(headlines_df[headlines_df[\"network\"] == network], test_size=0.2, random_state=123)\n",
    "    training_df = training_df[[\"headline\"]]\n",
    "    # add stop char so models have a sense for when headlines end\n",
    "    training_df[\"headline\"] = training_df[\"headline\"].astype(str) + f\" {STOP_CHAR}\"\n",
    "    \n",
    "    training_data = Dataset.from_pandas(training_df, preserve_index=False)\n",
    "\n",
    "    # have models generate a complete headline based on the first 4 words in each testing headline\n",
    "    testing_df[\"first_4_words_in_headline\"] = testing_df[\"headline\"].str.split().str[:4].str.join(\" \")\n",
    "    headlines = list(testing_df[\"first_4_words_in_headline\"].unique())\n",
    "\n",
    "    print(f\"{network} split into {len(training_data)} headlines to fine-tune and {len(headlines)} headline beginnings to generate new headlines\")\n",
    "\n",
    "    training_datasets[network] = training_data\n",
    "    testing_headlines[network] = headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00fdbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(headlines):\n",
    "    return base_model_tokenizer(headlines[\"headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22c03be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2789439654184066bd5e1e09a00c2e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a6f8762c314c3c9edd9774597ee120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe73bcedb3d4f42a9ca22dc74bd8606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac484dd4190541db9f54c8f62c265871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/6840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8ea67b9f4245e2bef61112ee39e1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1fb8bae6ca4a519cdfee793f1c9aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5052 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5aef19027324c7cac5c553adacdfdea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8474a87154cc4fb384b68db25d2ad04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eeb8d2059f44bdb35c8d85f2e551ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#I can do this with dictionary comprehension but I think it is more readable this way\n",
    "#tokenizing all the headlines\n",
    "tokenized_datasets = {}\n",
    "for network in networks:\n",
    "    tokenized_datasets[network] = training_datasets[network].map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbee0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping tokenized headlines together for the trainer, adding some padding to make sure all the lengths are the same\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    num_chunks = math.ceil(total_length / BLOCK_SIZE)\n",
    "    \n",
    "    # Split by chunks of max_len.\n",
    "    result = {k: [] for k in concatenated_examples.keys()}\n",
    "    result[\"labels\"] = []\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        for k, t in concatenated_examples.items():\n",
    "            chunk = t[i * BLOCK_SIZE : (i + 1) * BLOCK_SIZE]\n",
    "            # pad if chunk is shorter than BLOCK_SIZE\n",
    "            if len(chunk) < BLOCK_SIZE:\n",
    "                pad_len = BLOCK_SIZE - len(chunk)\n",
    "                chunk += [base_model_tokenizer.pad_token_id] * pad_len\n",
    "            result[k].append(chunk)\n",
    "        \n",
    "        label_chunk = result[\"input_ids\"][-1].copy()\n",
    "        #setting padding labels to -100 (-100 will be automatically ignore by PyTorch loss functions)\n",
    "        label_chunk = [token if token != base_model_tokenizer.pad_token_id else -100 for token in label_chunk]\n",
    "        result[\"labels\"].append(label_chunk)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef22b7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0c0d1f53934a9f94573d507a2cfc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256b8fdf864741448637cec47c3ed01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545e9f5ce3ed4a4d9d96f0fda39dbe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1274 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f34dbca1b604b3b885d2f2d564a3b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/6840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e39cb9bc764494d95515ea0427267ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5380 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7dc80c7107c4c679353738387b246b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5052 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c26d5df47314e27858a693a25faa7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145c2feb481044679c5f3b7731f1185f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd491328ce0b456683d3727f1910f4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets = {}\n",
    "for network in networks:\n",
    "    lm_datasets[network] = tokenized_datasets[network].map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        num_proc=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15d13a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_75157/241856275.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 02:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_75157/241856275.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='327' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [327/327 02:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_75157/241856275.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [72/72 00:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_75157/241856275.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='357' max='357' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [357/357 03:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_75157/241856275.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='345' max='345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [345/345 03:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_75157/241856275.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [264/264 02:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_75157/241856275.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [141/141 01:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_75157/241856275.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j1/8t43vbc17h30dc2rb39fstb00000gn/T/ipykernel_75157/241856275.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
      "/Users/franklinhuang/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='78' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [78/78 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for network in networks:\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(base_model_checkpoint)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        fine_tuned_model_name(network),\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        # push_to_hub=True,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=base_model,\n",
    "        args=training_args,\n",
    "        tokenizer=base_model_tokenizer,\n",
    "        train_dataset=lm_datasets[network]\n",
    "    )\n",
    "    trainer.train()\n",
    "    # trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3c9256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device: cpu\n",
      "generating 924 headlines for Breitbart\n",
      "generating 924 headlines in 29 batches\n",
      "starting batch 1/29\n",
      "starting batch 2/29\n",
      "starting batch 3/29\n",
      "starting batch 4/29\n",
      "starting batch 5/29\n",
      "starting batch 6/29\n",
      "starting batch 7/29\n",
      "starting batch 8/29\n",
      "starting batch 9/29\n",
      "starting batch 10/29\n",
      "starting batch 11/29\n",
      "starting batch 12/29\n",
      "starting batch 13/29\n",
      "starting batch 14/29\n",
      "starting batch 15/29\n",
      "starting batch 16/29\n",
      "starting batch 17/29\n",
      "starting batch 18/29\n",
      "starting batch 19/29\n",
      "starting batch 20/29\n",
      "starting batch 21/29\n",
      "starting batch 22/29\n",
      "starting batch 23/29\n",
      "starting batch 24/29\n",
      "starting batch 25/29\n",
      "starting batch 26/29\n",
      "starting batch 27/29\n",
      "starting batch 28/29\n",
      "starting batch 29/29\n",
      "finished Breitbart\n",
      "running on device: cpu\n",
      "generating 1334 headlines for Fox\n",
      "generating 1334 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "finished Fox\n",
      "running on device: cpu\n",
      "generating 319 headlines for MSNBC\n",
      "generating 319 headlines in 10 batches\n",
      "starting batch 1/10\n",
      "starting batch 2/10\n",
      "starting batch 3/10\n",
      "starting batch 4/10\n",
      "starting batch 5/10\n",
      "starting batch 6/10\n",
      "starting batch 7/10\n",
      "starting batch 8/10\n",
      "starting batch 9/10\n",
      "starting batch 10/10\n",
      "finished MSNBC\n",
      "running on device: cpu\n",
      "generating 1667 headlines for Newsmax\n",
      "generating 1667 headlines in 53 batches\n",
      "starting batch 1/53\n",
      "starting batch 2/53\n",
      "starting batch 3/53\n",
      "starting batch 4/53\n",
      "starting batch 5/53\n",
      "starting batch 6/53\n",
      "starting batch 7/53\n",
      "starting batch 8/53\n",
      "starting batch 9/53\n",
      "starting batch 10/53\n",
      "starting batch 11/53\n",
      "starting batch 12/53\n",
      "starting batch 13/53\n",
      "starting batch 14/53\n",
      "starting batch 15/53\n",
      "starting batch 16/53\n",
      "starting batch 17/53\n",
      "starting batch 18/53\n",
      "starting batch 19/53\n",
      "starting batch 20/53\n",
      "starting batch 21/53\n",
      "starting batch 22/53\n",
      "starting batch 23/53\n",
      "starting batch 24/53\n",
      "starting batch 25/53\n",
      "starting batch 26/53\n",
      "starting batch 27/53\n",
      "starting batch 28/53\n",
      "starting batch 29/53\n",
      "starting batch 30/53\n",
      "starting batch 31/53\n",
      "starting batch 32/53\n",
      "starting batch 33/53\n",
      "starting batch 34/53\n",
      "starting batch 35/53\n",
      "starting batch 36/53\n",
      "starting batch 37/53\n",
      "starting batch 38/53\n",
      "starting batch 39/53\n",
      "starting batch 40/53\n",
      "starting batch 41/53\n",
      "starting batch 42/53\n",
      "starting batch 43/53\n",
      "starting batch 44/53\n",
      "starting batch 45/53\n",
      "starting batch 46/53\n",
      "starting batch 47/53\n",
      "starting batch 48/53\n",
      "starting batch 49/53\n",
      "starting batch 50/53\n",
      "starting batch 51/53\n",
      "starting batch 52/53\n",
      "starting batch 53/53\n",
      "finished Newsmax\n",
      "running on device: cpu\n",
      "generating 1343 headlines for Nypost\n",
      "generating 1343 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "finished Nypost\n",
      "running on device: cpu\n",
      "generating 1240 headlines for NYT\n",
      "generating 1240 headlines in 39 batches\n",
      "starting batch 1/39\n",
      "starting batch 2/39\n",
      "starting batch 3/39\n",
      "starting batch 4/39\n",
      "starting batch 5/39\n",
      "starting batch 6/39\n",
      "starting batch 7/39\n",
      "starting batch 8/39\n",
      "starting batch 9/39\n",
      "starting batch 10/39\n",
      "starting batch 11/39\n",
      "starting batch 12/39\n",
      "starting batch 13/39\n",
      "starting batch 14/39\n",
      "starting batch 15/39\n",
      "starting batch 16/39\n",
      "starting batch 17/39\n",
      "starting batch 18/39\n",
      "starting batch 19/39\n",
      "starting batch 20/39\n",
      "starting batch 21/39\n",
      "starting batch 22/39\n",
      "starting batch 23/39\n",
      "starting batch 24/39\n",
      "starting batch 25/39\n",
      "starting batch 26/39\n",
      "starting batch 27/39\n",
      "starting batch 28/39\n",
      "starting batch 29/39\n",
      "starting batch 30/39\n",
      "starting batch 31/39\n",
      "starting batch 32/39\n",
      "starting batch 33/39\n",
      "starting batch 34/39\n",
      "starting batch 35/39\n",
      "starting batch 36/39\n",
      "starting batch 37/39\n",
      "starting batch 38/39\n",
      "starting batch 39/39\n",
      "finished NYT\n",
      "running on device: cpu\n",
      "generating 797 headlines for USAToday\n",
      "generating 797 headlines in 25 batches\n",
      "starting batch 1/25\n",
      "starting batch 2/25\n",
      "starting batch 3/25\n",
      "starting batch 4/25\n",
      "starting batch 5/25\n",
      "starting batch 6/25\n",
      "starting batch 7/25\n",
      "starting batch 8/25\n",
      "starting batch 9/25\n",
      "starting batch 10/25\n",
      "starting batch 11/25\n",
      "starting batch 12/25\n",
      "starting batch 13/25\n",
      "starting batch 14/25\n",
      "starting batch 15/25\n",
      "starting batch 16/25\n",
      "starting batch 17/25\n",
      "starting batch 18/25\n",
      "starting batch 19/25\n",
      "starting batch 20/25\n",
      "starting batch 21/25\n",
      "starting batch 22/25\n",
      "starting batch 23/25\n",
      "starting batch 24/25\n",
      "starting batch 25/25\n",
      "finished USAToday\n",
      "running on device: cpu\n",
      "generating 668 headlines for Washpost\n",
      "generating 668 headlines in 21 batches\n",
      "starting batch 1/21\n",
      "starting batch 2/21\n",
      "starting batch 3/21\n",
      "starting batch 4/21\n",
      "starting batch 5/21\n",
      "starting batch 6/21\n",
      "starting batch 7/21\n",
      "starting batch 8/21\n",
      "starting batch 9/21\n",
      "starting batch 10/21\n",
      "starting batch 11/21\n",
      "starting batch 12/21\n",
      "starting batch 13/21\n",
      "starting batch 14/21\n",
      "starting batch 15/21\n",
      "starting batch 16/21\n",
      "starting batch 17/21\n",
      "starting batch 18/21\n",
      "starting batch 19/21\n",
      "starting batch 20/21\n",
      "starting batch 21/21\n",
      "finished Washpost\n",
      "running on device: cpu\n",
      "generating 412 headlines for WSJ\n",
      "generating 412 headlines in 13 batches\n",
      "starting batch 1/13\n",
      "starting batch 2/13\n",
      "starting batch 3/13\n",
      "starting batch 4/13\n",
      "starting batch 5/13\n",
      "starting batch 6/13\n",
      "starting batch 7/13\n",
      "starting batch 8/13\n",
      "starting batch 9/13\n",
      "starting batch 10/13\n",
      "starting batch 11/13\n",
      "starting batch 12/13\n",
      "starting batch 13/13\n",
      "finished WSJ\n"
     ]
    }
   ],
   "source": [
    "generated_headline_dfs = []\n",
    "\n",
    "for network in networks:\n",
    "    model_name = \"franzhanz/\" + fine_tuned_model_name(network)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    print(f\"running on device: {device}\")\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    headlines = testing_headlines[network]\n",
    "    print(f\"generating {len(headlines)} headlines for {network}\")\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    num_batches = (len(headlines) + batch_size - 1) // batch_size\n",
    "    print(f\"generating {len(headlines)} headlines in {num_batches} batches\")\n",
    "\n",
    "    generated_headlines = []\n",
    "    for i in range(num_batches):\n",
    "        print(f\"starting batch {i + 1}/{num_batches}\")\n",
    "\n",
    "        start = i * batch_size\n",
    "        end = min(start + batch_size, len(headlines))\n",
    "        batch_headlines = headlines[start:end]\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            batch_headlines,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=64\n",
    "        )\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=64,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.9\n",
    "        )\n",
    "\n",
    "        results = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        results = [re.sub(r'\\s+', ' ', r).strip() for r in results]\n",
    "        generated_headlines += results\n",
    "\n",
    "    print(f\"finished {network}\")\n",
    "    generated_headlines = [headline.strip() for headline in generated_headlines]\n",
    "\n",
    "    #format the generated headlines for a csv\n",
    "    generated_df = pd.DataFrame({\"headline\": generated_headlines})\n",
    "    generated_df[\"year\"] = 2025\n",
    "    generated_df[\"month\"] = 10\n",
    "    generated_df[\"day\"] = 10\n",
    "    generated_df[\"network\"] = network\n",
    "    generated_df[\"url\"] = \"generated_headline\"\n",
    "    generated_df[\"news_category\"] = \"politics\"\n",
    "\n",
    "    generated_headline_dfs.append(generated_df)\n",
    "\n",
    "pd.concat(generated_headline_dfs).to_csv(GENERATED_HEADLINES_FILE_NAME, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd613ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding pos_neg_neu sentiment for Breitbart headlines on 2025-10-10\n",
      "added 924 pos_neg_neu sentiments for Breitbart headlines on 2025-10-10\n",
      "finding emotion sentiment for Breitbart headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 924 headlines in 29 batches\n",
      "starting batch 1/29\n",
      "starting batch 2/29\n",
      "starting batch 3/29\n",
      "starting batch 4/29\n",
      "starting batch 5/29\n",
      "starting batch 6/29\n",
      "starting batch 7/29\n",
      "starting batch 8/29\n",
      "starting batch 9/29\n",
      "starting batch 10/29\n",
      "starting batch 11/29\n",
      "starting batch 12/29\n",
      "starting batch 13/29\n",
      "starting batch 14/29\n",
      "starting batch 15/29\n",
      "starting batch 16/29\n",
      "starting batch 17/29\n",
      "starting batch 18/29\n",
      "starting batch 19/29\n",
      "starting batch 20/29\n",
      "starting batch 21/29\n",
      "starting batch 22/29\n",
      "starting batch 23/29\n",
      "starting batch 24/29\n",
      "starting batch 25/29\n",
      "starting batch 26/29\n",
      "starting batch 27/29\n",
      "starting batch 28/29\n",
      "starting batch 29/29\n",
      "Finished processing 924 headlines\n",
      "finding pos_neg_neu sentiment for Fox headlines on 2025-10-10\n",
      "added 1334 pos_neg_neu sentiments for Fox headlines on 2025-10-10\n",
      "finding emotion sentiment for Fox headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1334 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "Finished processing 1334 headlines\n",
      "finding pos_neg_neu sentiment for MSNBC headlines on 2025-10-10\n",
      "added 319 pos_neg_neu sentiments for MSNBC headlines on 2025-10-10\n",
      "finding emotion sentiment for MSNBC headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 319 headlines in 10 batches\n",
      "starting batch 1/10\n",
      "starting batch 2/10\n",
      "starting batch 3/10\n",
      "starting batch 4/10\n",
      "starting batch 5/10\n",
      "starting batch 6/10\n",
      "starting batch 7/10\n",
      "starting batch 8/10\n",
      "starting batch 9/10\n",
      "starting batch 10/10\n",
      "Finished processing 319 headlines\n",
      "finding pos_neg_neu sentiment for Newsmax headlines on 2025-10-10\n",
      "added 1667 pos_neg_neu sentiments for Newsmax headlines on 2025-10-10\n",
      "finding emotion sentiment for Newsmax headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1667 headlines in 53 batches\n",
      "starting batch 1/53\n",
      "starting batch 2/53\n",
      "starting batch 3/53\n",
      "starting batch 4/53\n",
      "starting batch 5/53\n",
      "starting batch 6/53\n",
      "starting batch 7/53\n",
      "starting batch 8/53\n",
      "starting batch 9/53\n",
      "starting batch 10/53\n",
      "starting batch 11/53\n",
      "starting batch 12/53\n",
      "starting batch 13/53\n",
      "starting batch 14/53\n",
      "starting batch 15/53\n",
      "starting batch 16/53\n",
      "starting batch 17/53\n",
      "starting batch 18/53\n",
      "starting batch 19/53\n",
      "starting batch 20/53\n",
      "starting batch 21/53\n",
      "starting batch 22/53\n",
      "starting batch 23/53\n",
      "starting batch 24/53\n",
      "starting batch 25/53\n",
      "starting batch 26/53\n",
      "starting batch 27/53\n",
      "starting batch 28/53\n",
      "starting batch 29/53\n",
      "starting batch 30/53\n",
      "starting batch 31/53\n",
      "starting batch 32/53\n",
      "starting batch 33/53\n",
      "starting batch 34/53\n",
      "starting batch 35/53\n",
      "starting batch 36/53\n",
      "starting batch 37/53\n",
      "starting batch 38/53\n",
      "starting batch 39/53\n",
      "starting batch 40/53\n",
      "starting batch 41/53\n",
      "starting batch 42/53\n",
      "starting batch 43/53\n",
      "starting batch 44/53\n",
      "starting batch 45/53\n",
      "starting batch 46/53\n",
      "starting batch 47/53\n",
      "starting batch 48/53\n",
      "starting batch 49/53\n",
      "starting batch 50/53\n",
      "starting batch 51/53\n",
      "starting batch 52/53\n",
      "starting batch 53/53\n",
      "Finished processing 1667 headlines\n",
      "finding pos_neg_neu sentiment for Nypost headlines on 2025-10-10\n",
      "added 1343 pos_neg_neu sentiments for Nypost headlines on 2025-10-10\n",
      "finding emotion sentiment for Nypost headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1343 headlines in 42 batches\n",
      "starting batch 1/42\n",
      "starting batch 2/42\n",
      "starting batch 3/42\n",
      "starting batch 4/42\n",
      "starting batch 5/42\n",
      "starting batch 6/42\n",
      "starting batch 7/42\n",
      "starting batch 8/42\n",
      "starting batch 9/42\n",
      "starting batch 10/42\n",
      "starting batch 11/42\n",
      "starting batch 12/42\n",
      "starting batch 13/42\n",
      "starting batch 14/42\n",
      "starting batch 15/42\n",
      "starting batch 16/42\n",
      "starting batch 17/42\n",
      "starting batch 18/42\n",
      "starting batch 19/42\n",
      "starting batch 20/42\n",
      "starting batch 21/42\n",
      "starting batch 22/42\n",
      "starting batch 23/42\n",
      "starting batch 24/42\n",
      "starting batch 25/42\n",
      "starting batch 26/42\n",
      "starting batch 27/42\n",
      "starting batch 28/42\n",
      "starting batch 29/42\n",
      "starting batch 30/42\n",
      "starting batch 31/42\n",
      "starting batch 32/42\n",
      "starting batch 33/42\n",
      "starting batch 34/42\n",
      "starting batch 35/42\n",
      "starting batch 36/42\n",
      "starting batch 37/42\n",
      "starting batch 38/42\n",
      "starting batch 39/42\n",
      "starting batch 40/42\n",
      "starting batch 41/42\n",
      "starting batch 42/42\n",
      "Finished processing 1343 headlines\n",
      "finding pos_neg_neu sentiment for NYT headlines on 2025-10-10\n",
      "added 1240 pos_neg_neu sentiments for NYT headlines on 2025-10-10\n",
      "finding emotion sentiment for NYT headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 1240 headlines in 39 batches\n",
      "starting batch 1/39\n",
      "starting batch 2/39\n",
      "starting batch 3/39\n",
      "starting batch 4/39\n",
      "starting batch 5/39\n",
      "starting batch 6/39\n",
      "starting batch 7/39\n",
      "starting batch 8/39\n",
      "starting batch 9/39\n",
      "starting batch 10/39\n",
      "starting batch 11/39\n",
      "starting batch 12/39\n",
      "starting batch 13/39\n",
      "starting batch 14/39\n",
      "starting batch 15/39\n",
      "starting batch 16/39\n",
      "starting batch 17/39\n",
      "starting batch 18/39\n",
      "starting batch 19/39\n",
      "starting batch 20/39\n",
      "starting batch 21/39\n",
      "starting batch 22/39\n",
      "starting batch 23/39\n",
      "starting batch 24/39\n",
      "starting batch 25/39\n",
      "starting batch 26/39\n",
      "starting batch 27/39\n",
      "starting batch 28/39\n",
      "starting batch 29/39\n",
      "starting batch 30/39\n",
      "starting batch 31/39\n",
      "starting batch 32/39\n",
      "starting batch 33/39\n",
      "starting batch 34/39\n",
      "starting batch 35/39\n",
      "starting batch 36/39\n",
      "starting batch 37/39\n",
      "starting batch 38/39\n",
      "starting batch 39/39\n",
      "Finished processing 1240 headlines\n",
      "finding pos_neg_neu sentiment for USAToday headlines on 2025-10-10\n",
      "added 797 pos_neg_neu sentiments for USAToday headlines on 2025-10-10\n",
      "finding emotion sentiment for USAToday headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 797 headlines in 25 batches\n",
      "starting batch 1/25\n",
      "starting batch 2/25\n",
      "starting batch 3/25\n",
      "starting batch 4/25\n",
      "starting batch 5/25\n",
      "starting batch 6/25\n",
      "starting batch 7/25\n",
      "starting batch 8/25\n",
      "starting batch 9/25\n",
      "starting batch 10/25\n",
      "starting batch 11/25\n",
      "starting batch 12/25\n",
      "starting batch 13/25\n",
      "starting batch 14/25\n",
      "starting batch 15/25\n",
      "starting batch 16/25\n",
      "starting batch 17/25\n",
      "starting batch 18/25\n",
      "starting batch 19/25\n",
      "starting batch 20/25\n",
      "starting batch 21/25\n",
      "starting batch 22/25\n",
      "starting batch 23/25\n",
      "starting batch 24/25\n",
      "starting batch 25/25\n",
      "Finished processing 797 headlines\n",
      "finding pos_neg_neu sentiment for Washpost headlines on 2025-10-10\n",
      "added 668 pos_neg_neu sentiments for Washpost headlines on 2025-10-10\n",
      "finding emotion sentiment for Washpost headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 668 headlines in 21 batches\n",
      "starting batch 1/21\n",
      "starting batch 2/21\n",
      "starting batch 3/21\n",
      "starting batch 4/21\n",
      "starting batch 5/21\n",
      "starting batch 6/21\n",
      "starting batch 7/21\n",
      "starting batch 8/21\n",
      "starting batch 9/21\n",
      "starting batch 10/21\n",
      "starting batch 11/21\n",
      "starting batch 12/21\n",
      "starting batch 13/21\n",
      "starting batch 14/21\n",
      "starting batch 15/21\n",
      "starting batch 16/21\n",
      "starting batch 17/21\n",
      "starting batch 18/21\n",
      "starting batch 19/21\n",
      "starting batch 20/21\n",
      "starting batch 21/21\n",
      "Finished processing 668 headlines\n",
      "finding pos_neg_neu sentiment for WSJ headlines on 2025-10-10\n",
      "added 412 pos_neg_neu sentiments for WSJ headlines on 2025-10-10\n",
      "finding emotion sentiment for WSJ headlines on 2025-10-10\n",
      "running on device: cpu\n",
      "processing 412 headlines in 13 batches\n",
      "starting batch 1/13\n",
      "starting batch 2/13\n",
      "starting batch 3/13\n",
      "starting batch 4/13\n",
      "starting batch 5/13\n",
      "starting batch 6/13\n",
      "starting batch 7/13\n",
      "starting batch 8/13\n",
      "starting batch 9/13\n",
      "starting batch 10/13\n",
      "starting batch 11/13\n",
      "starting batch 12/13\n",
      "starting batch 13/13\n",
      "Finished processing 412 headlines\n"
     ]
    }
   ],
   "source": [
    "from lib.sentiment_analysis import find_pos_neg_neu_sentiment, find_emotion_sentiment\n",
    "\n",
    "for network in networks:\n",
    "    find_pos_neg_neu_sentiment(network, 2025, 10, 10, use_generated_headlines=True)\n",
    "    find_emotion_sentiment(network, 2025, 10, 10, use_generated_headlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90937467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
